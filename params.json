{"name":"Mechanical Understanding of Contextual Knowledge","tagline":"","body":"What is MUCK?\r\n=============\r\n\r\nMUCK is software for making sense out of massive, messy collections of documents.  This toolkit can be used to take directories of unwieldy amounts of texts, extract useful information (both metadata and linguistic features like parts-of-speech, named entities, and parsed dependencies), and construct a comprehensible database with all extracted information readibly available.  You can also use this toolkit to build classifiers from random subsets of this database (as well as classify the rest of the documents in the database) relatively easily...just not quite yet.\r\n\r\n##History\r\n\r\nMUCK was initially written to handle large collections of news content\r\nand government data, such as newspaper archives, Congressional press\r\nreleases/floor speeches, and legislation.  The toolkit was designed to answer many different questions that required natural language understanding of these texts, such as which Congressmen get the most news attention and under what conditions.\r\n\r\n##Authors\r\n\r\nMUCK was created by Nick Nugent, [Rebecca Weiss], and [Sean Westwood].\r\n\r\n##Version\r\n\r\nCurrently not even in alpha with no immediate plans for release.  Use at your own\r\nrisk!\r\n\r\n##Tech\r\n\r\nMUCK uses a lot of open-source libraries:\r\n\r\n* [Apache Software Foundation] - [Lucene] for text indexing\r\n* [Stanford NLP group] - [JavaNLP] and [Classifier] for natural language processing\r\nand machine learning capability.\r\n* [10Gen] - documents are stored in [MongoDB]\r\n\r\nMUCK was designed for use on [AWS] platforms,\r\nand can scale up by distributing across EC2 instances.  This means that you can add and remove nodes depending on your task.\r\n\r\nMUCK is also intended to complement [Amazon Mechanical Turk], primarily for creating training data needed in classification tasks (topics, sentiment, etc).\r\n\r\n##Installation\r\n\r\nYou can  ``git clone git@github.com:rjweiss/MUCK-toolkit.git``.  But\r\nyou probably won't want to, since you will need to download and maintain your own dependencies and build from source on your own system. If you run into problems, you are unfortunately on your own.  We break this toolkit on a regular basis with our own projects, so there's no guarantee that we will be able to solve problems encountered on other people's systems. \r\n\r\n##License\r\n\r\n[MIT].  This is free and open-source.  \r\n\r\n[Rebecca Weiss]: http://www.stanford.edu/~rjweiss\r\n[Sean Westwood]: http://www.stanford.edu/~seanjw\r\n[Apache Software Foundation]: http://www.apache.org/\r\n[Lucene]: http://lucene.apache.org/\r\n[Stanford NLP group]: http://www-nlp.stanford.edu/\r\n[JavaNLP]: http://nlp.stanford.edu/software/corenlp.shtml\r\n[Classifier]: http://nlp.stanford.edu/software/classifier.html\r\n[10Gen]: http://www.10gen.com\r\n[MongoDB]: http://www.mongodb.org\r\n[MIT]: http://opensource.org/licenses/MIT\r\n[AWS]: http://aws.amazon.com\r\n[Amazon Mechanical Turk]: http://www.mturk.com","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}