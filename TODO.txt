
Next:
  set up worker server to start in worker ami
  worker ami should not have a copy of the raw data or db volumes
  finish creating new amazon linux ami, updating readme

  write code to reinsert dropped tasks into the queue
  gracefully handle network disconnects

  add mechanism for feeding new tasks into the server manually/interactively

  verify whether manually created & attached volumes get destroyed when an instance is terminated
  add gc data to logs

  handle duplicate inserts...?  check fs against mongo for directory traversal before scheduling jobs?
  write a script to copy and install project files to server

  sampling:
    give each article an integer id, these should be consecutive
    sampling should select a uniform distribution from 1 to N.
    doesn't really need to export the whole entity, probably just pubdate, mediasource, filename, headline, and text
    List<Article> sample(int sampleSize);

Remember:
  Whenever the project files are updated, you need a new AMI.

Investigate:
  CoreNlpTask.execute(): /news/data/latimes/2000/20000129/1105885/txt/48562238.xml
  Unknown variable: TWILIGHT
  CoreNlpTask.execute(): /news/data/latimes/2000/20000129/1105885/txt/48562331.xml
  Unknown variable: WEEKDAY

